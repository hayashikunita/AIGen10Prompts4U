import streamlit as st
import json
from pathlib import Path
import random
from datetime import datetime
import os
from openai import OpenAI
from dotenv import load_dotenv
import pandas as pd
import io
import pdfplumber
from docx import Document

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="AIGen10Prompts4U - ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ",
    page_icon="ğŸ¤–",
    layout="wide"
)

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
CHAT_HISTORY_DIR = Path("chat_history")
CHAT_HISTORY_DIR.mkdir(exist_ok=True)

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ä¿å­˜ã™ã‚‹é–¢æ•°
def save_chat_history(title, messages, selected_prompt=None):
    """ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{title}_{timestamp}.json"
    filepath = CHAT_HISTORY_DIR / filename
    
    history_data = {
        "title": title,
        "timestamp": timestamp,
        "messages": messages,
        "selected_prompt": selected_prompt
    }
    
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(history_data, f, ensure_ascii=False, indent=2)
    
    return filepath

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ä¸€è¦§ã‚’å–å¾—ã™ã‚‹é–¢æ•°
def list_chat_histories():
    """ä¿å­˜ã•ã‚ŒãŸãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®ãƒªã‚¹ãƒˆã‚’å–å¾—"""
    histories = []
    for filepath in sorted(CHAT_HISTORY_DIR.glob("*.json"), reverse=True):
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
                histories.append({
                    "filename": filepath.name,
                    "filepath": filepath,
                    "title": data.get("title", "ç„¡é¡Œ"),
                    "timestamp": data.get("timestamp", ""),
                    "message_count": len(data.get("messages", []))
                })
        except Exception as e:
            continue
    return histories

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’èª­ã¿è¾¼ã‚€é–¢æ•°
def load_chat_history(filepath):
    """æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’èª­ã¿è¾¼ã‚€"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        st.error(f"å±¥æ­´ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return None

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’å‰Šé™¤ã™ã‚‹é–¢æ•°
def delete_chat_history(filepath):
    """æŒ‡å®šã•ã‚ŒãŸãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’å‰Šé™¤"""
    try:
        filepath.unlink()
        return True
    except Exception as e:
        st.error(f"å±¥æ­´ã®å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return False

# OpenAI APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
def get_openai_client():
    api_key = os.getenv("OPENAI_API_KEY")
    if api_key:
        return OpenAI(api_key=api_key)
    return None

# ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’æ¦‚ç®—ã™ã‚‹é–¢æ•°ï¼ˆ1ãƒˆãƒ¼ã‚¯ãƒ³ â‰’ 4æ–‡å­—ï¼‰
def estimate_tokens(text):
    """ãƒ†ã‚­ã‚¹ãƒˆã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’æ¦‚ç®—"""
    return len(text) // 4

# ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’åˆ‡ã‚Šè©°ã‚ã‚‹é–¢æ•°
def truncate_content(content, max_tokens=15000):
    """
    ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒå¤§ãã™ãã‚‹å ´åˆã«åˆ‡ã‚Šè©°ã‚ã‚‹
    max_tokens: æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ15000 â‰’ 60,000æ–‡å­—ï¼‰
    """
    estimated_tokens = estimate_tokens(content)
    
    if estimated_tokens <= max_tokens:
        return content, False  # åˆ‡ã‚Šè©°ã‚ãªã—
    
    # åˆ‡ã‚Šè©°ã‚ã‚‹
    max_chars = max_tokens * 4
    truncated = content[:max_chars]
    
    # æœ€å¾Œã®æ”¹è¡Œã§åˆ‡ã‚‹ï¼ˆé€”ä¸­ã§åˆ‡ã‚Œãªã„ã‚ˆã†ã«ï¼‰
    last_newline = truncated.rfind('\n')
    if last_newline > max_chars * 0.9:  # 90%ä»¥ä¸Šã®ä½ç½®ã«æ”¹è¡ŒãŒã‚ã‚Œã°
        truncated = truncated[:last_newline]
    
    return truncated, True  # åˆ‡ã‚Šè©°ã‚ã‚ã‚Š

# ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’èª­ã¿å–ã‚‹é–¢æ•°
def read_file_content(uploaded_file):
    """
    ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’èª­ã¿å–ã‚Šã€ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã§è¿”ã™
    Excelã€CSVã€PDFã€Wordã€ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾å¿œ
    """
    file_name = uploaded_file.name
    file_extension = Path(file_name).suffix.lower()
    
    try:
        # PDFãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆ
        if file_extension == '.pdf':
            uploaded_file.seek(0)
            text_parts = []
            with pdfplumber.open(uploaded_file) as pdf:
                for i, page in enumerate(pdf.pages, 1):
                    page_text = page.extract_text()
                    if page_text:
                        text_parts.append(f"\n--- ãƒšãƒ¼ã‚¸ {i} ---\n{page_text}")
            
            if text_parts:
                content = "".join(text_parts)
                content += f"\n\n(ç·ãƒšãƒ¼ã‚¸æ•°: {len(pdf.pages)})"
                return content, "pdf"
            else:
                return None, "error: PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ"
        
        # Wordãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆ
        elif file_extension in ['.docx', '.doc']:
            uploaded_file.seek(0)
            if file_extension == '.docx':
                doc = Document(uploaded_file)
                text_parts = []
                for i, para in enumerate(doc.paragraphs, 1):
                    if para.text.strip():
                        text_parts.append(para.text)
                
                content = "\n".join(text_parts)
                if content.strip():
                    content += f"\n\n(æ®µè½æ•°: {len([p for p in doc.paragraphs if p.text.strip()])})"
                    return content, "word"
                else:
                    return None, "error: Wordãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ"
            else:
                return None, "error: .docå½¢å¼ã¯éå¯¾å¿œã§ã™ã€‚.docxå½¢å¼ã«å¤‰æ›ã—ã¦ãã ã•ã„"
        
        # Excelãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆ
        elif file_extension in ['.xlsx', '.xls']:
            uploaded_file.seek(0)
            df_dict = pd.read_excel(uploaded_file, sheet_name=None)
            
            content_parts = []
            for sheet_name, df in df_dict.items():
                content_parts.append(f"\n=== ã‚·ãƒ¼ãƒˆ: {sheet_name} ===\n")
                content_parts.append(df.to_string(index=False))
                content_parts.append(f"\n(è¡Œæ•°: {len(df)}, åˆ—æ•°: {len(df.columns)})\n")
            
            return "".join(content_parts), "excel"
        
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆ
        elif file_extension == '.csv':
            uploaded_file.seek(0)
            for encoding in ['utf-8', 'shift_jis', 'cp932']:
                try:
                    uploaded_file.seek(0)
                    df = pd.read_csv(uploaded_file, encoding=encoding)
                    content = f"\n{df.to_string(index=False)}\n(è¡Œæ•°: {len(df)}, åˆ—æ•°: {len(df.columns)})\n"
                    return content, "csv"
                except UnicodeDecodeError:
                    continue
            return None, "error: CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’åˆ¤åˆ¥ã§ãã¾ã›ã‚“ã§ã—ãŸ"
        
        # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆ
        else:
            uploaded_file.seek(0)
            # è¤‡æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è©¦ã™
            for encoding in ['utf-8', 'shift_jis', 'cp932', 'latin-1']:
                try:
                    uploaded_file.seek(0)
                    content = uploaded_file.read().decode(encoding)
                    return content, "text"
                except UnicodeDecodeError:
                    continue
            return None, "error: ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’åˆ¤åˆ¥ã§ãã¾ã›ã‚“ã§ã—ãŸ"
            
    except Exception as e:
        return None, f"error: {str(e)}"

class PromptGenerator:
    def __init__(self):
        self.prompts_dir = Path("prompts_data")
        self.file_map = {
            "industry": "industry.json",
            "idea": "idea.json",
            "management": "management.json",
            "sales": "sales.json",
            "summary": "summary.json",
            "engineer": "engineer.json",
            "email": "email.json",
            "negotiation": "negotiation.json",
            "meeting": "meeting.json",
            "consultant": "consultant.json",
            "medical": "medical.json",
            "investment": "investment.json",
            "dating": "dating.json",
            "job_interview": "job_interview.json",
            "education": "education.json",
            "legal": "legal.json",
            "sns_content": "sns_content.json",
            "startup": "startup.json",
            "programmer": "programmer.json",
            "python_engineer": "python_engineer.json",
            "ai_engineer": "ai_engineer.json",
            "chatgpt_api": "chatgpt_api.json",
            "lawyer": "lawyer.json",
            "it_lawyer": "it_lawyer.json",
            "ceo": "ceo.json",
            "stock_trader": "stock_trader.json",
            "finance": "finance.json",
            "qol": "qol.json"
        }
        
        self.category_names = {
            "industry": "æ¥­ç•Œåˆ†æãƒ»å¸‚å ´èª¿æŸ»ç”¨",
            "idea": "ã‚¢ã‚¤ãƒ‡ã‚¢å‰µå‡ºç”¨",
            "management": "ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆç”¨",
            "sales": "å–¶æ¥­ãƒ»ã‚»ãƒ¼ãƒ«ã‚¹ç”¨",
            "summary": "è¦ç´„ãƒ»ã¾ã¨ã‚ç”¨",
            "engineer": "ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ç”¨",
            "email": "ãƒ¡ãƒ¼ãƒ«è¿”ä¿¡ç”¨",
            "negotiation": "ä¾¡æ ¼äº¤æ¸‰ç”¨",
            "meeting": "ä¼šè­°æº–å‚™ç”¨",
            "consultant": "ã‚³ãƒ³ã‚µãƒ«ãƒ†ã‚£ãƒ³ã‚°ç”¨",
            "medical": "åŒ»ç™‚ãƒ»å¥åº·ç›¸è«‡ç”¨",
            "investment": "æŠ•è³‡ãƒ»è³‡ç”£é‹ç”¨ç”¨",
            "dating": "æ‹æ„›ãƒ»ãƒ‡ãƒ¼ãƒˆç”¨",
            "job_interview": "é¢æ¥ãƒ»è»¢è·å¯¾ç­–ç”¨",
            "education": "æ•™è‚²ãƒ»å­¦ç¿’æ”¯æ´ç”¨",
            "legal": "æ³•å¾‹ãƒ»å¥‘ç´„æ›¸ç”¨",
            "sns_content": "SNSãƒ»ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ä½œæˆç”¨",
            "startup": "èµ·æ¥­ãƒ»ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ç”¨",
            "programmer": "ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼å®Ÿè·µç”¨",
            "python_engineer": "Pythonã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢å°‚é–€ç”¨",
            "ai_engineer": "AIã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢å°‚é–€ç”¨",
            "chatgpt_api": "ChatGPT APIæ´»ç”¨å°‚é–€ç”¨",
            "lawyer": "æ³•å¾‹å®¶ãƒ»å¼è­·å£«å®Ÿè·µç”¨",
            "it_lawyer": "ITæ³•å‹™ãƒ»ãƒ†ãƒƒã‚¯æ³•å¾‹å®¶å°‚é–€ç”¨",
            "ceo": "çµŒå–¶è€…ãƒ»CEOå®Ÿè·µç”¨",
            "stock_trader": "æ—¥æœ¬æ ªãƒˆãƒ¬ãƒ¼ãƒ€ãƒ¼å®Ÿè·µç”¨",
            "finance": "é‡‘èæ¥­ç•Œãƒ»éŠ€è¡Œå®Ÿè·µç”¨",
            "qol": "QOLå‘ä¸Šãƒ»ãƒ©ã‚¤ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«æ”¹å–„ç”¨"
        }

    def load_prompts(self, category):
        """æŒ‡å®šã‚«ãƒ†ã‚´ãƒªã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’èª­ã¿è¾¼ã‚€"""
        file_name = self.file_map.get(category)
        if not file_name:
            return None
        
        file_path = self.prompts_dir / file_name
        if not file_path.exists():
            return None
        
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        return data

    def generate_prompts(self, category, count=10):
        """ãƒ©ãƒ³ãƒ€ãƒ ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ"""
        data = self.load_prompts(category)
        if not data:
            return None
        
        prompts = data.get("prompts", [])
        if not prompts:
            return None
        
        # ãƒ©ãƒ³ãƒ€ãƒ ã«é¸æŠ
        selected = random.sample(prompts, min(count, len(prompts)))
        return {
            "category": data.get("category", category),
            "prompts": selected
        }

# Streamlitã‚¢ãƒ—ãƒª
def main():
    st.title("ğŸ¤– AIGen10Prompts4U")
    st.markdown("### ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã‚¢ãƒ—ãƒª")
    st.markdown("---")
    
    generator = PromptGenerator()
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    if "mode" not in st.session_state:
        st.session_state.mode = "generator"  # generator ã¾ãŸã¯ chatbot
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "selected_prompt" not in st.session_state:
        st.session_state.selected_prompt = None
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        st.header("âš™ï¸ è¨­å®š")
        
        # ãƒ¢ãƒ¼ãƒ‰é¸æŠ
        current_mode = st.session_state.get("mode", "generator")
        mode = st.radio(
            "ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ",
            options=["generator", "chatbot"],
            format_func=lambda x: "ğŸ² ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ" if x == "generator" else "ğŸ’¬ ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ",
            index=0 if current_mode == "generator" else 1,
            key="mode_selector"
        )
        
        # ãƒ¢ãƒ¼ãƒ‰ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã®ã¿æ›´æ–°
        if mode != st.session_state.mode:
            st.session_state.mode = mode
        
        st.markdown("---")
        
        if st.session_state.mode == "generator":
            # ã‚«ãƒ†ã‚´ãƒªé¸æŠ
            category = st.selectbox(
                "ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠ",
                options=list(generator.file_map.keys()),
                format_func=lambda x: f"{x} ({generator.category_names.get(x, x)})"
            )
            
            # ç”Ÿæˆæ•°ã¯æœ€å¤§å€¤ã«å›ºå®š(å„ã‚«ãƒ†ã‚´ãƒªã®å…¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ)
            data = generator.load_prompts(category)
            count = len(data.get("prompts", [])) if data else 10
            st.info(f"ğŸ“Š ç”Ÿæˆæ•°: {count}å€‹ï¼ˆå…¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰")
            
            # ç”Ÿæˆãƒœã‚¿ãƒ³
            generate_button = st.button("ğŸ² ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ", type="primary", use_container_width=True)
        else:
            # ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆè¨­å®š
            st.markdown("**ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆè¨­å®š**")
            
            # API ã‚­ãƒ¼ç¢ºèª
            client = get_openai_client()
            if client:
                st.success("âœ… OpenAI API æ¥ç¶šæ¸ˆã¿")
            else:
                st.warning("âš ï¸ OpenAI APIã‚­ãƒ¼ãŒæœªè¨­å®šã§ã™")
                st.markdown("`.env`ãƒ•ã‚¡ã‚¤ãƒ«ã«`OPENAI_API_KEY`ã‚’è¨­å®šã—ã¦ãã ã•ã„")
        
        st.markdown("---")
        st.markdown("**çµ±è¨ˆæƒ…å ±**")
        st.info(f"ğŸ“Š åˆè¨ˆ22ã‚«ãƒ†ã‚´ãƒª\n\nğŸ“ åˆè¨ˆ780å€‹ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")
    
    # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
    if st.session_state.mode == "generator":
        show_generator_mode(generator, generate_button if 'generate_button' in locals() else False, 
                          category if 'category' in locals() else None, 
                          count if 'count' in locals() else 10)
    else:
        show_chatbot_mode(generator)

def switch_to_chat(prompt):
    """ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆã‚‹"""
    st.session_state.selected_prompt = prompt
    st.session_state.messages = []
    st.session_state.mode = "chatbot"

def show_generator_mode(generator, generate_button, category, count):
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆãƒ¢ãƒ¼ãƒ‰"""
    if generate_button:
        with st.spinner("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆä¸­..."):
            result = generator.generate_prompts(category, count)
            
            if result:
                st.success(f"âœ… {len(result['prompts'])}å€‹ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
                st.markdown(f"**ã‚«ãƒ†ã‚´ãƒª:** {result['category']}")
                st.markdown("---")
                
                # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¸€è¦§ã‚’è¡¨ç¤º
                st.markdown("### ğŸ“ ç”Ÿæˆã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")
                for i, prompt in enumerate(result['prompts'], 1):
                    with st.expander(f"**{i}. {prompt['title']}**"):
                        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                        st.markdown("##### ğŸ“‹ ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ")
                        st.text_area(
                            "ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
                            value=prompt['system_prompt'],
                            height=150,
                            key=f"prompt_text_{i}_{hash(prompt['title'])}",
                            label_visibility="collapsed"
                        )
                        
                        # æ¨å¥¨æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«
                        st.markdown("##### ğŸ“ æ¨å¥¨æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«")
                        attachments = prompt.get('recommended_attachments', [])
                        if attachments:
                            for attachment in attachments:
                                st.markdown(f"â€¢ {attachment}")
                        else:
                            st.info("ãªã—")
                        
                        # ãƒãƒ£ãƒƒãƒˆãƒœã‚¿ãƒ³
                        st.markdown("---")
                        button_key = f"chat_expand_{i}_{hash(prompt['title'])}"
                        if st.button("ğŸ’¬ ã“ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ãƒãƒ£ãƒƒãƒˆ", key=button_key, type="primary", use_container_width=True, on_click=switch_to_chat, args=(prompt,)):
                            pass  # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§å‡¦ç†
            else:
                st.error("âŒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
    else:
        # åˆæœŸè¡¨ç¤º
        st.info("ğŸ‘ˆ å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã‚«ãƒ†ã‚´ãƒªã¨ç”Ÿæˆæ•°ã‚’é¸æŠã—ã€ã€Œãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„")
        
        # ã‚«ãƒ†ã‚´ãƒªä¸€è¦§ã‚’è¡¨ç¤º
        st.markdown("### ğŸ“š åˆ©ç”¨å¯èƒ½ãªã‚«ãƒ†ã‚´ãƒª")
        
        col1, col2, col3 = st.columns(3)
        
        categories = list(generator.category_names.items())
        
        with col1:
            st.markdown("#### ãƒ“ã‚¸ãƒã‚¹ç³»")
            for cat, name in categories[:8]:
                st.markdown(f"â€¢ **{cat}**: {name}")
        
        with col2:
            st.markdown("#### å®Ÿå‹™ãƒ»å°‚é–€ç³»")
            for cat, name in categories[8:15]:
                st.markdown(f"â€¢ **{cat}**: {name}")
        
        with col3:
            st.markdown("#### æŠ€è¡“ç³»")
            for cat, name in categories[15:]:
                st.markdown(f"â€¢ **{cat}**: {name}")

def show_chatbot_mode(generator):
    """ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆãƒ¢ãƒ¼ãƒ‰"""
    client = get_openai_client()
    
    # ä¸Šéƒ¨ã«ãƒœã‚¿ãƒ³ã‚’é…ç½®
    col1, col2, col3, col4 = st.columns([2, 2, 2, 1])
    
    with col1:
        if st.button("ğŸ“‹ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰é¸æŠ", use_container_width=True):
            st.session_state.show_prompt_selector = True
            st.rerun()
    
    with col2:
        if st.button("ğŸ†• æ–°ã—ã„ä¼šè©±", use_container_width=True):
            st.session_state.messages = []
            st.session_state.selected_prompt = None
            st.rerun()
    
    with col3:
        # ç¾åœ¨ã®ä¼šè©±ã‚’ä¿å­˜
        if st.button("ğŸ’¾ ä¼šè©±ã‚’ä¿å­˜", use_container_width=True, disabled=len(st.session_state.messages) == 0):
            st.session_state.show_save_dialog = True
    
    with col4:
        # å±¥æ­´ã‚’è¡¨ç¤º
        if st.button("ğŸ“š", use_container_width=True, help="å±¥æ­´ã‚’è¡¨ç¤º"):
            st.session_state.show_history = not st.session_state.get('show_history', False)
            st.rerun()
    
    # ä¼šè©±ä¿å­˜ãƒ€ã‚¤ã‚¢ãƒ­ã‚°
    if st.session_state.get('show_save_dialog', False):
        with st.expander("ğŸ’¾ ä¼šè©±ã‚’ä¿å­˜", expanded=True):
            save_title = st.text_input("ã‚¿ã‚¤ãƒˆãƒ«", value=f"ä¼šè©±_{datetime.now().strftime('%Y%m%d_%H%M')}")
            
            col_save1, col_save2 = st.columns(2)
            with col_save1:
                if st.button("ğŸ’¾ ä¿å­˜", type="primary", use_container_width=True):
                    filepath = save_chat_history(
                        save_title,
                        st.session_state.messages,
                        st.session_state.selected_prompt
                    )
                    st.success(f"âœ… ä¿å­˜ã—ã¾ã—ãŸ: {filepath.name}")
                    st.session_state.show_save_dialog = False
                    st.rerun()
            
            with col_save2:
                if st.button("âŒ ã‚­ãƒ£ãƒ³ã‚»ãƒ«", use_container_width=True):
                    st.session_state.show_save_dialog = False
                    st.rerun()
    
    # å±¥æ­´è¡¨ç¤º
    if st.session_state.get('show_history', False):
        with st.expander("ğŸ“š ä¼šè©±å±¥æ­´", expanded=True):
            histories = list_chat_histories()
            
            if histories:
                st.markdown(f"**ä¿å­˜ã•ã‚ŒãŸä¼šè©±: {len(histories)}ä»¶**")
                
                for hist in histories:
                    col_h1, col_h2, col_h3 = st.columns([3, 1, 1])
                    
                    with col_h1:
                        # ã‚¿ã‚¤ãƒˆãƒ«ã¨æƒ…å ±
                        timestamp_str = datetime.strptime(hist['timestamp'], "%Y%m%d_%H%M%S").strftime("%Y/%m/%d %H:%M")
                        st.markdown(f"**{hist['title']}**")
                        st.caption(f"ğŸ“… {timestamp_str} | ğŸ’¬ {hist['message_count']}ä»¶ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸")
                    
                    with col_h2:
                        # èª­ã¿è¾¼ã¿ãƒœã‚¿ãƒ³
                        if st.button("ğŸ“‚ èª­è¾¼", key=f"load_{hist['filename']}", use_container_width=True):
                            data = load_chat_history(hist['filepath'])
                            if data:
                                st.session_state.messages = data.get('messages', [])
                                st.session_state.selected_prompt = data.get('selected_prompt')
                                st.session_state.show_history = False
                                st.success(f"âœ… {hist['title']} ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
                                st.rerun()
                    
                    with col_h3:
                        # å‰Šé™¤ãƒœã‚¿ãƒ³
                        if st.button("ğŸ—‘ï¸", key=f"delete_{hist['filename']}", use_container_width=True, help="å‰Šé™¤"):
                            if delete_chat_history(hist['filepath']):
                                st.success(f"âœ… {hist['title']} ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
                                st.rerun()
                    
                    st.markdown("---")
            else:
                st.info("ä¿å­˜ã•ã‚ŒãŸä¼šè©±ã¯ã‚ã‚Šã¾ã›ã‚“")
            
            if st.button("âŒ é–‰ã˜ã‚‹", use_container_width=True):
                st.session_state.show_history = False
                st.rerun()
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé¸æŠãƒ€ã‚¤ã‚¢ãƒ­ã‚°
    if hasattr(st.session_state, 'show_prompt_selector') and st.session_state.show_prompt_selector:
        with st.expander("ğŸ“‹ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é¸æŠ", expanded=True):
            category = st.selectbox(
                "ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠ",
                options=list(generator.file_map.keys()),
                format_func=lambda x: f"{generator.category_names.get(x, x)}",
                key="prompt_selector_category"
            )
            
            data = generator.load_prompts(category)
            if data:
                prompts = data.get("prompts", [])
                prompt_titles = [p['title'] for p in prompts]
                
                selected_title = st.selectbox(
                    "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é¸æŠ",
                    options=prompt_titles,
                    key="prompt_selector_title"
                )
                
                if st.button("âœ… ã“ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨", type="primary"):
                    selected_prompt = next((p for p in prompts if p['title'] == selected_title), None)
                    if selected_prompt:
                        st.session_state.selected_prompt = selected_prompt
                        st.session_state.messages = []
                        st.session_state.show_prompt_selector = False
                        st.rerun()
            
            if st.button("âŒ ã‚­ãƒ£ãƒ³ã‚»ãƒ«"):
                st.session_state.show_prompt_selector = False
                st.rerun()
    
    # é¸æŠã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¡¨ç¤º
    if st.session_state.selected_prompt:
        with st.expander("ğŸ“‹ ä½¿ç”¨ä¸­ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ", expanded=False):
            st.markdown(f"**ã‚¿ã‚¤ãƒˆãƒ«:** {st.session_state.selected_prompt['title']}")
            st.text_area(
                "ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
                value=st.session_state.selected_prompt['system_prompt'],
                height=150,
                disabled=True,
                key="current_system_prompt"
            )
            
            # æ¨å¥¨æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¡¨ç¤º
            st.markdown("**ğŸ“ æ¨å¥¨æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«:**")
            attachments = st.session_state.selected_prompt.get('recommended_attachments', [])
            if attachments:
                for attachment in attachments:
                    st.markdown(f"â€¢ {attachment}")
            else:
                st.info("ãªã—")
    
    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’è¡¨ç¤º
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            # æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’è¡¨ç¤º
            if "files" in message and message["files"]:
                st.markdown("**ğŸ“ æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«:**")
                for file_info in message["files"]:
                    st.markdown(f"â€¢ {file_info['name']} ({file_info['size']} bytes)")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼
    uploaded_files = st.file_uploader(
        "ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ·»ä»˜ï¼ˆè¤‡æ•°å¯ï¼‰",
        accept_multiple_files=True,
        key="file_uploader",
        help="PDFã€Word (.docx)ã€Excel (.xlsx, .xls)ã€CSVã€ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã€ã‚³ãƒ¼ãƒ‰ãªã©ã«å¯¾å¿œ"
    )
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
    if prompt := st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."):
        if not client:
            st.error("âŒ OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚`.env`ãƒ•ã‚¡ã‚¤ãƒ«ã«`OPENAI_API_KEY`ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
            return
        
        # æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’èª­ã¿å–ã‚‹
        file_contents = []
        file_info_list = []
        total_truncated = False
        
        if uploaded_files:
            for uploaded_file in uploaded_files:
                # æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿å–ã‚Šé–¢æ•°ã‚’ä½¿ç”¨
                content, file_type = read_file_content(uploaded_file)
                
                if content:
                    # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’åˆ‡ã‚Šè©°ã‚ã‚‹ï¼ˆ1ãƒ•ã‚¡ã‚¤ãƒ«ã‚ãŸã‚Šæœ€å¤§15000ãƒˆãƒ¼ã‚¯ãƒ³ â‰’ 60KBï¼‰
                    truncated_content, was_truncated = truncate_content(content, max_tokens=15000)
                    
                    if was_truncated:
                        total_truncated = True
                    
                    # æˆåŠŸã—ãŸå ´åˆ
                    truncate_notice = " âš ï¸ (ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤§ãã„ãŸã‚ä¸€éƒ¨çœç•¥ã•ã‚Œã¾ã—ãŸ)" if was_truncated else ""
                    
                    if file_type == "pdf":
                        file_contents.append(f"\n\n--- ğŸ“• {uploaded_file.name} (PDFãƒ•ã‚¡ã‚¤ãƒ«){truncate_notice} ---\n{truncated_content}")
                    elif file_type == "word":
                        file_contents.append(f"\n\n--- ğŸ“˜ {uploaded_file.name} (Wordãƒ•ã‚¡ã‚¤ãƒ«){truncate_notice} ---\n{truncated_content}")
                    elif file_type == "excel":
                        file_contents.append(f"\n\n--- ğŸ“Š {uploaded_file.name} (Excelãƒ•ã‚¡ã‚¤ãƒ«){truncate_notice} ---\n{truncated_content}")
                    elif file_type == "csv":
                        file_contents.append(f"\n\n--- ğŸ“„ {uploaded_file.name} (CSVãƒ•ã‚¡ã‚¤ãƒ«){truncate_notice} ---\n{truncated_content}")
                    else:  # text
                        file_contents.append(f"\n\n--- ğŸ“ {uploaded_file.name} (ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«){truncate_notice} ---\n{truncated_content}")
                    
                    file_info_list.append({
                        "name": uploaded_file.name,
                        "size": uploaded_file.size,
                        "type": file_type,
                        "truncated": was_truncated
                    })
                else:
                    # èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ãŸå ´åˆ
                    error_msg = f"âš ï¸ {uploaded_file.name} ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ"
                    if "error:" in file_type:
                        error_msg += f" ({file_type})"
                    file_contents.append(f"\n\n--- {error_msg} ---")
                    file_info_list.append({
                        "name": uploaded_file.name,
                        "size": uploaded_file.size,
                        "type": "error"
                    })
        
        # è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
        if total_truncated:
            st.warning("âš ï¸ ä¸€éƒ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤§ãã™ãã‚‹ãŸã‚ã€å†…å®¹ã®ä¸€éƒ¨ãŒçœç•¥ã•ã‚Œã¾ã—ãŸã€‚ã‚ˆã‚Šè©³ç´°ãªåˆ†æãŒå¿…è¦ãªå ´åˆã¯ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†å‰²ã—ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’è¿½åŠ 
        full_prompt = prompt
        if file_contents:
            full_prompt += "\n\n" + "".join(file_contents)
        
        # å…¨ä½“ã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’ãƒã‚§ãƒƒã‚¯
        total_tokens = estimate_tokens(full_prompt)
        if total_tokens > 25000:  # 25,000ãƒˆãƒ¼ã‚¯ãƒ³ä»¥ä¸Šã®å ´åˆã¯è­¦å‘Š
            st.error(f"âŒ å…¥åŠ›ãŒå¤§ãã™ãã¾ã™ï¼ˆæ¨å®š {total_tokens:,} ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰ã€‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†å‰²ã™ã‚‹ã‹ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’æ¸›ã‚‰ã—ã¦ãã ã•ã„ã€‚")
            return
        elif total_tokens > 20000:  # 20,000ãƒˆãƒ¼ã‚¯ãƒ³ä»¥ä¸Šã®å ´åˆã¯æ³¨æ„å–šèµ·
            st.warning(f"âš ï¸ å…¥åŠ›ãŒå¤§ãã„ã§ã™ï¼ˆæ¨å®š {total_tokens:,} ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰ã€‚å‡¦ç†ã«æ™‚é–“ãŒã‹ã‹ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
        user_message = {"role": "user", "content": full_prompt}
        if file_info_list:
            user_message["files"] = file_info_list
        
        st.session_state.messages.append(user_message)
        with st.chat_message("user"):
            st.markdown(prompt)
            if file_info_list:
                st.markdown("**ğŸ“ æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«:**")
                for file_info in file_info_list:
                    st.markdown(f"â€¢ {file_info['name']} ({file_info['size']} bytes)")
        
        # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¿œç­”ã‚’ç”Ÿæˆ
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""
            
            # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å«ã‚ã¦APIå‘¼ã³å‡ºã—
            messages = []
            if st.session_state.selected_prompt:
                messages.append({
                    "role": "system",
                    "content": st.session_state.selected_prompt['system_prompt']
                })
            
            messages.extend([
                {"role": m["role"], "content": m["content"]}
                for m in st.session_state.messages
            ])
            
            try:
                stream = client.chat.completions.create(
                    # model="chatgpt-4o-latest",
                    model="gpt-5",
                    messages=messages,
                    stream=True,
                    # temperature=0.7
                )
                
                for chunk in stream:
                    if chunk.choices[0].delta.content is not None:
                        full_response += chunk.choices[0].delta.content
                        message_placeholder.markdown(full_response + "â–Œ")
                
                message_placeholder.markdown(full_response)
                
            except Exception as e:
                full_response = f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
                message_placeholder.markdown(full_response)
            
            # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
            st.session_state.messages.append({"role": "assistant", "content": full_response})
    
    # åˆæœŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    if len(st.session_state.messages) == 0:
        st.info("ğŸ’¬ ãƒãƒ£ãƒƒãƒˆã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ã€Œãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‹ã‚‰é¸æŠã€ã§ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¨­å®šã§ãã¾ã™ã€‚")

if __name__ == "__main__":
    main()
